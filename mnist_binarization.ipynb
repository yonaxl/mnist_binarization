{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 724us/step - loss: 0.2891 - accuracy: 0.9136\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.1232 - accuracy: 0.9611\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0846 - accuracy: 0.9731\n",
      "313/313 [==============================] - 0s 425us/step - loss: 0.1163 - accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11630675196647644, 0.9635999798774719]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tf.keras.Sequential()\n",
    "clf.add(tf.keras.layers.Flatten())\n",
    "#clf.add(tf.keras.Input(shape=(28,28)))\n",
    "\n",
    "clf.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "clf.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "clf.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "clf.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "clf.fit(x=x_train, y=y_train, epochs=3)\n",
    "clf.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is where I performed threhsolding based on a value to the features and get binary values instead. The general idea is to remove some granularity level and potential noise by binarizing pixels above a certain threshold value only. We will experiment with classifier trained on the same binarized training set and the one trained without binarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration with thresh value = 0\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 730us/step - loss: 0.2460 - accuracy: 0.9256\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 730us/step - loss: 0.1166 - accuracy: 0.9634\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 723us/step - loss: 0.0828 - accuracy: 0.9741\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 439us/step - loss: 2.3852 - accuracy: 0.0834\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 467us/step - loss: 0.0967 - accuracy: 0.9684\n",
      "iteration with thresh value = 0.25\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 760us/step - loss: 0.2544 - accuracy: 0.9240\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 732us/step - loss: 0.1042 - accuracy: 0.9681\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 0.0693 - accuracy: 0.9771\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 433us/step - loss: 2.3549 - accuracy: 0.0884\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 437us/step - loss: 0.1023 - accuracy: 0.9703\n",
      "iteration with thresh value = 0.4\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 731us/step - loss: 0.5945 - accuracy: 0.8128\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 745us/step - loss: 0.3730 - accuracy: 0.8794\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 734us/step - loss: 0.3005 - accuracy: 0.9014\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 434us/step - loss: 2.3188 - accuracy: 0.0950\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 432us/step - loss: 0.3988 - accuracy: 0.8699\n",
      "iteration with thresh value = 0.5\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 725us/step - loss: 0.9463 - accuracy: 0.6902\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.7229 - accuracy: 0.7570\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 729us/step - loss: 0.6465 - accuracy: 0.7797\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 471us/step - loss: 2.3041 - accuracy: 0.1132\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 469us/step - loss: 0.7516 - accuracy: 0.7504\n",
      "iteration with thresh value = 0.6\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 783us/step - loss: 1.2563 - accuracy: 0.5855\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 754us/step - loss: 1.0663 - accuracy: 0.6403\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 1.0062 - accuracy: 0.6558\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 433us/step - loss: 2.3022 - accuracy: 0.1341\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 432us/step - loss: 1.0833 - accuracy: 0.6381\n",
      "iteration with thresh value = 0.75\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 724us/step - loss: 1.7241 - accuracy: 0.4021\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 713us/step - loss: 1.5885 - accuracy: 0.4398\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 1.5557 - accuracy: 0.4485\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 435us/step - loss: 2.3032 - accuracy: 0.1431\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 436us/step - loss: 1.6080 - accuracy: 0.4404\n"
     ]
    }
   ],
   "source": [
    "t_list = [0, 0.25, 0.4, 0.5, 0.6, 0.75]\n",
    "for thresh in t_list:\n",
    "    print(\"iteration with thresh value = \" + str(thresh))\n",
    "    clf2 = tf.keras.Sequential()\n",
    "    clf2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    clf2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    clf2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    clf2.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "    clf2.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    x_test2 = np.array((x_test > thresh).astype(int))\n",
    "    x_train2 = np.array((x_train > thresh).astype(int))\n",
    "    clf2.fit(x=x_train2, y=y_train, epochs=3)\n",
    "    print(\"Model Trained without thresholding\")\n",
    "    clf.evaluate(x_test2, y_test)\n",
    "    print(\"Model Trained with thresholding\")\n",
    "    clf2.evaluate(x_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section experiment with pixel value amplification. The pixel value is amplified by a certain factor to increase the difference to the background color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration with thresh value = 1.5\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 724us/step - loss: 0.2457 - accuracy: 0.9268\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 730us/step - loss: 0.1011 - accuracy: 0.9686\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.0694 - accuracy: 0.9776\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 420us/step - loss: 99.7141 - accuracy: 0.9531\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 428us/step - loss: 63.8698 - accuracy: 0.9563\n",
      "iteration with thresh value = 2\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 726us/step - loss: 0.2413 - accuracy: 0.9291\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.1020 - accuracy: 0.9692\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 722us/step - loss: 0.0693 - accuracy: 0.9780\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 435us/step - loss: 72.5179 - accuracy: 0.9507\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 437us/step - loss: 28.2196 - accuracy: 0.9551\n",
      "iteration with thresh value = 3\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 746us/step - loss: 0.2270 - accuracy: 0.9304\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 722us/step - loss: 0.0963 - accuracy: 0.9704\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 732us/step - loss: 0.0673 - accuracy: 0.9788\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 427us/step - loss: 75.3936 - accuracy: 0.9481\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 429us/step - loss: 20.1692 - accuracy: 0.9556\n",
      "iteration with thresh value = 5\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.2168 - accuracy: 0.9334\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 732us/step - loss: 0.0971 - accuracy: 0.9695\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.0686 - accuracy: 0.9780\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 432us/step - loss: 75.6558 - accuracy: 0.9477\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 442us/step - loss: 16.2999 - accuracy: 0.9469\n"
     ]
    }
   ],
   "source": [
    "t_list = [1.5, 2, 3, 5]\n",
    "for thresh in t_list:\n",
    "    print(\"iteration with thresh value = \" + str(thresh))\n",
    "    clf2 = tf.keras.Sequential()\n",
    "    clf2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    clf2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    clf2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    clf2.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "    clf2.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    x_test2 = np.array((x_test * thresh))\n",
    "    x_train2 = np.array((x_train * thresh))\n",
    "    clf2.fit(x=x_train2, y=y_train, epochs=3)\n",
    "    print(\"Model Trained without thresholding\")\n",
    "    clf.evaluate(x_test2, y_test)\n",
    "    print(\"Model Trained with thresholding\")\n",
    "    clf2.evaluate(x_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration with thresh value = 1\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.2647 - accuracy: 0.9225\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 720us/step - loss: 0.1057 - accuracy: 0.9672\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 704us/step - loss: 0.0731 - accuracy: 0.9769\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 410us/step - loss: 0.0970 - accuracy: 0.9693\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 428us/step - loss: 0.0908 - accuracy: 0.9725\n",
      "iteration with thresh value = 2\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.2659 - accuracy: 0.9222\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 739us/step - loss: 0.1077 - accuracy: 0.9662\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 735us/step - loss: 0.0746 - accuracy: 0.9762\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 425us/step - loss: 0.0970 - accuracy: 0.9693\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 429us/step - loss: 0.0892 - accuracy: 0.9703\n",
      "iteration with thresh value = 3\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.2668 - accuracy: 0.9225\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 730us/step - loss: 0.1082 - accuracy: 0.9674\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 716us/step - loss: 0.0732 - accuracy: 0.9768\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 424us/step - loss: 0.0970 - accuracy: 0.9693\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 497us/step - loss: 0.0981 - accuracy: 0.9689\n",
      "iteration with thresh value = 5\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 711us/step - loss: 0.2653 - accuracy: 0.9216\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 705us/step - loss: 0.1107 - accuracy: 0.9659\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 721us/step - loss: 0.0744 - accuracy: 0.9775\n",
      "Model Trained without thresholding\n",
      "313/313 [==============================] - 0s 423us/step - loss: 0.0970 - accuracy: 0.9693\n",
      "Model Trained with thresholding\n",
      "313/313 [==============================] - 0s 433us/step - loss: 0.1004 - accuracy: 0.9670\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "# x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "t_list = [1, 2, 3, 5]\n",
    "for thresh in t_list:\n",
    "    print(\"iteration with thresh value = \" + str(thresh))\n",
    "    clf2 = tf.keras.Sequential()\n",
    "    clf2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    clf2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    clf2.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    clf2.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "    clf2.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    x_test2 = np.array((x_test ** thresh))\n",
    "    x_train2 = np.array((x_train ** thresh))\n",
    "    x_train2 = tf.keras.utils.normalize(x_train, axis=1)\n",
    "    x_test2 = tf.keras.utils.normalize(x_test, axis=1)\n",
    "    clf2.fit(x=x_train2, y=y_train, epochs=3)\n",
    "    print(\"Model Trained without thresholding\")\n",
    "    clf.evaluate(x_test2, y_test)\n",
    "    print(\"Model Trained with thresholding\")\n",
    "    clf2.evaluate(x_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section will attempt to perform data selection on the training set to improve knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1976 - accuracy: 0.9404\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0801 - accuracy: 0.9749\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0512 - accuracy: 0.9835\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0381 - accuracy: 0.9882\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0277 - accuracy: 0.9910\n",
      "313/313 [==============================] - 0s 708us/step - loss: 0.0916 - accuracy: 0.9770\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2021 - accuracy: 0.9392\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0784 - accuracy: 0.9755\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0516 - accuracy: 0.9832\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0385 - accuracy: 0.9872\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "313/313 [==============================] - 0s 749us/step - loss: 0.0991 - accuracy: 0.9736\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2013 - accuracy: 0.9392\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0800 - accuracy: 0.9750\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0509 - accuracy: 0.9828\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0372 - accuracy: 0.9879\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0284 - accuracy: 0.9908\n",
      "313/313 [==============================] - 0s 772us/step - loss: 0.0776 - accuracy: 0.9803\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2014 - accuracy: 0.9403\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0815 - accuracy: 0.9743\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0526 - accuracy: 0.9829\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0363 - accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0261 - accuracy: 0.9916\n",
      "313/313 [==============================] - 0s 776us/step - loss: 0.0960 - accuracy: 0.9773\n",
      "-----------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2026 - accuracy: 0.9391\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0808 - accuracy: 0.9743\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0519 - accuracy: 0.9834\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0361 - accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0285 - accuracy: 0.9903\n",
      "313/313 [==============================] - 0s 725us/step - loss: 0.0779 - accuracy: 0.9783\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for rs in range(5):        \n",
    "        tf.random.set_seed(rs)\n",
    "        clf = tf.keras.Sequential()\n",
    "        clf.add(tf.keras.layers.Flatten())\n",
    "        #clf.add(tf.keras.Input(shape=(28,28)))\n",
    "\n",
    "        clf.add(tf.keras.layers.Dense(756, activation='relu'))\n",
    "        clf.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        clf.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "        clf.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "        clf.fit(x=x_train, y=y_train, epochs=5)\n",
    "        clf.evaluate(x_test, y_test)\n",
    "        print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0392 - accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.039233263581991196, 0.9878000020980835]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 686us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = clf  # include here your original model\n",
    "\n",
    "layer_name = 'dense_1'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>3.093845</td>\n",
       "      <td>2.533580</td>\n",
       "      <td>2.127861</td>\n",
       "      <td>1.584220</td>\n",
       "      <td>5.487467</td>\n",
       "      <td>2.748890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.495983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.128837</td>\n",
       "      <td>1.556001</td>\n",
       "      <td>0.203703</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.668021</td>\n",
       "      <td>0.816934</td>\n",
       "      <td>0.516019</td>\n",
       "      <td>3.089105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.791188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.877966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.403624</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584236</td>\n",
       "      <td>2.594068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.352109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.542666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.804542</td>\n",
       "      <td>1.211046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.841309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463794</td>\n",
       "      <td>1.042605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188526</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>2.246238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.226999</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350691</td>\n",
       "      <td>0.707122</td>\n",
       "      <td>1.253813</td>\n",
       "      <td>1.629533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>1.154916</td>\n",
       "      <td>0.200052</td>\n",
       "      <td>0.214410</td>\n",
       "      <td>8</td>\n",
       "      <td>59995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1.076001</td>\n",
       "      <td>1.528402</td>\n",
       "      <td>3.656946</td>\n",
       "      <td>0.928550</td>\n",
       "      <td>1.555840</td>\n",
       "      <td>3.350775</td>\n",
       "      <td>3.146987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.984097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.203707</td>\n",
       "      <td>3</td>\n",
       "      <td>59996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.857539</td>\n",
       "      <td>2.860135</td>\n",
       "      <td>1.015597</td>\n",
       "      <td>2.128629</td>\n",
       "      <td>2.184263</td>\n",
       "      <td>4.353489</td>\n",
       "      <td>2.408435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.701233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>59997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.697838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.423297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.978252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.052868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>59998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>2.750190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.565820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178376</td>\n",
       "      <td>1.657946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>59999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.404365  3.093845  2.533580  2.127861  1.584220  5.487467  2.748890   \n",
       "1      0.000000  0.999957  0.000000  0.632427  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.273043  0.000000  1.668021  0.816934  0.516019   \n",
       "3      0.000000  1.584236  2.594068  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  2.542666  0.000000  1.804542  1.211046  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59995  2.246238  0.000000  1.226999  0.397359  0.000000  1.350691  0.707122   \n",
       "59996  1.076001  1.528402  3.656946  0.928550  1.555840  3.350775  3.146987   \n",
       "59997  0.857539  2.860135  1.015597  2.128629  2.184263  4.353489  2.408435   \n",
       "59998  0.000000  0.979816  0.000000  1.697838  0.000000  0.000000  0.000000   \n",
       "59999  2.750190  0.000000  0.999666  0.000000  0.000000  1.565820  0.000000   \n",
       "\n",
       "              7         8         9  ...       120  121       122  123  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.165331  0.0  2.495983  0.0   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0   \n",
       "2      3.089105  0.000000  3.791188  ...  0.225551  0.0  0.000000  0.0   \n",
       "3      2.352109  0.000000  0.209048  ...  0.904559  0.0  0.000000  0.0   \n",
       "4      1.841309  0.000000  0.000000  ...  0.000000  0.0  0.000000  0.0   \n",
       "...         ...       ...       ...  ...       ...  ...       ...  ...   \n",
       "59995  1.253813  1.629533  0.000000  ...  0.083639  0.0  0.579547  0.0   \n",
       "59996  0.000000  0.207704  0.000000  ...  1.984097  0.0  0.000000  0.0   \n",
       "59997  0.000000  0.000000  0.000000  ...  0.000000  0.0  3.701233  0.0   \n",
       "59998  0.000000  0.000000  2.098446  ...  0.000000  0.0  1.423297  0.0   \n",
       "59999  0.542547  0.000000  0.000000  ...  0.000000  0.0  0.865995  0.0   \n",
       "\n",
       "            124       125       126       127  label  index  \n",
       "0      0.000000  0.000000  0.000000  0.000000      5      0  \n",
       "1      0.006000  1.128837  1.556001  0.203703      0      1  \n",
       "2      1.877966  0.000000  0.000000  4.403624      4      2  \n",
       "3      0.132883  0.000000  0.000000  0.866146      1      3  \n",
       "4      0.463794  1.042605  0.000000  0.188526      9      4  \n",
       "...         ...       ...       ...       ...    ...    ...  \n",
       "59995  0.142081  1.154916  0.200052  0.214410      8  59995  \n",
       "59996  0.000000  0.583714  0.000000  1.203707      3  59996  \n",
       "59997  0.000000  0.000000  0.757499  0.000000      5  59997  \n",
       "59998  1.978252  0.000000  3.052868  0.000000      6  59998  \n",
       "59999  0.178376  1.657946  0.000000  0.000000      8  59999  \n",
       "\n",
       "[60000 rows x 130 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "features = pd.DataFrame(intermediate_output)\n",
    "features['label'] = y_train\n",
    "features['index'] = features.index\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_labels = np.unique(features['label'])\n",
    "\n",
    "x_train_selected = []\n",
    "\n",
    "def compute_mse(df, mean):\n",
    "    mse = []\n",
    "    for n in range(len(df)):\n",
    "        # measure the mse from each data point to the class mean\n",
    "        mse.append((np.square(df.iloc[n,:-1] - mean)).mean())\n",
    "    return mse\n",
    "\n",
    "for i in u_labels:\n",
    "    temp = features[features['label'] == i].drop(['label'], axis=1)\n",
    "    mean_i = np.mean(temp.iloc[:,:-1], axis=0)\n",
    "    temp['mse'] = compute_mse(temp, mean_i)\n",
    "    x_train_selected.append(temp)\n",
    "\n",
    "x_train_new = pd.concat(x_train_selected, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29999.500000</td>\n",
       "      <td>0.303764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17320.652413</td>\n",
       "      <td>0.222711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14999.750000</td>\n",
       "      <td>0.150908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29999.500000</td>\n",
       "      <td>0.242192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44999.250000</td>\n",
       "      <td>0.386080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59999.000000</td>\n",
       "      <td>3.314142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index           mse\n",
       "count  60000.000000  60000.000000\n",
       "mean   29999.500000      0.303764\n",
       "std    17320.652413      0.222711\n",
       "min        0.000000      0.024024\n",
       "25%    14999.750000      0.150908\n",
       "50%    29999.500000      0.242192\n",
       "75%    44999.250000      0.386080\n",
       "max    59999.000000      3.314142"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new = x_train_new[['index', 'mse']]\n",
    "x_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1            1\n",
       "51          51\n",
       "95          95\n",
       "320        320\n",
       "326        326\n",
       "         ...  \n",
       "59650    59650\n",
       "59749    59749\n",
       "59756    59756\n",
       "59888    59888\n",
       "59890    59890\n",
       "Name: index, Length: 6231, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_t = 0.1\n",
    "new_index = x_train_new[x_train_new['mse']< new_t]['index']\n",
    "new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1423 - accuracy: 0.9559\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0423 - accuracy: 0.9854\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0257 - accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0200 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0156 - accuracy: 0.9946\n",
      "313/313 [==============================] - 0s 758us/step - loss: 0.1966 - accuracy: 0.9655\n",
      "this is for t =  0.9\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.1663 - accuracy: 0.9476\n",
      "Epoch 2/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0551 - accuracy: 0.9816\n",
      "Epoch 3/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0352 - accuracy: 0.9881\n",
      "Epoch 4/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0251 - accuracy: 0.9915\n",
      "Epoch 5/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0206 - accuracy: 0.9931\n",
      "313/313 [==============================] - 0s 750us/step - loss: 0.1318 - accuracy: 0.9713\n",
      "this is for t =  0.95\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.1814 - accuracy: 0.9437\n",
      "Epoch 2/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0672 - accuracy: 0.9779\n",
      "Epoch 3/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0422 - accuracy: 0.9857\n",
      "Epoch 4/5\n",
      "1838/1838 [==============================] - 3s 2ms/step - loss: 0.0316 - accuracy: 0.9891\n",
      "Epoch 5/5\n",
      "1838/1838 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9922\n",
      "313/313 [==============================] - 0s 755us/step - loss: 0.1196 - accuracy: 0.9715\n",
      "this is for t =  0.98\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.1919 - accuracy: 0.9408\n",
      "Epoch 2/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0728 - accuracy: 0.9764\n",
      "Epoch 3/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0477 - accuracy: 0.9843\n",
      "Epoch 4/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0338 - accuracy: 0.9885\n",
      "Epoch 5/5\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 0.0251 - accuracy: 0.9913\n",
      "313/313 [==============================] - 0s 763us/step - loss: 0.0971 - accuracy: 0.9752\n",
      "this is for t =  0.99\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.2002 - accuracy: 0.9402\n",
      "Epoch 2/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0778 - accuracy: 0.9758\n",
      "Epoch 3/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0509 - accuracy: 0.9837\n",
      "Epoch 4/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0373 - accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0281 - accuracy: 0.9907\n",
      "313/313 [==============================] - 0s 784us/step - loss: 0.0881 - accuracy: 0.9758\n",
      "this is for t =  0.999\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1436 - accuracy: 0.9541\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0413 - accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0274 - accuracy: 0.9906\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0156 - accuracy: 0.9944\n",
      "313/313 [==============================] - 0s 724us/step - loss: 0.1865 - accuracy: 0.9657\n",
      "this is for t =  0.9\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.1680 - accuracy: 0.9472\n",
      "Epoch 2/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0572 - accuracy: 0.9810\n",
      "Epoch 3/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0353 - accuracy: 0.9882\n",
      "Epoch 4/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0256 - accuracy: 0.9912\n",
      "Epoch 5/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9926\n",
      "313/313 [==============================] - 0s 844us/step - loss: 0.1271 - accuracy: 0.9699\n",
      "this is for t =  0.95\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.1822 - accuracy: 0.9435\n",
      "Epoch 2/5\n",
      "1838/1838 [==============================] - 3s 2ms/step - loss: 0.0679 - accuracy: 0.9776\n",
      "Epoch 3/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0429 - accuracy: 0.9861\n",
      "Epoch 4/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9897\n",
      "Epoch 5/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0230 - accuracy: 0.9922\n",
      "313/313 [==============================] - 0s 778us/step - loss: 0.1334 - accuracy: 0.9716\n",
      "this is for t =  0.98\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.1921 - accuracy: 0.9409\n",
      "Epoch 2/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0731 - accuracy: 0.9767\n",
      "Epoch 3/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0461 - accuracy: 0.9846\n",
      "Epoch 4/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0322 - accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 0.0269 - accuracy: 0.9908\n",
      "313/313 [==============================] - 0s 774us/step - loss: 0.0868 - accuracy: 0.9776\n",
      "this is for t =  0.99\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.2018 - accuracy: 0.9393\n",
      "Epoch 2/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0803 - accuracy: 0.9746\n",
      "Epoch 3/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0519 - accuracy: 0.9833\n",
      "Epoch 4/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0367 - accuracy: 0.9882\n",
      "Epoch 5/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0277 - accuracy: 0.9907\n",
      "313/313 [==============================] - 0s 759us/step - loss: 0.1173 - accuracy: 0.9682\n",
      "this is for t =  0.999\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1435 - accuracy: 0.9550\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0443 - accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0256 - accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0151 - accuracy: 0.9948\n",
      "313/313 [==============================] - 0s 786us/step - loss: 0.2165 - accuracy: 0.9613\n",
      "this is for t =  0.9\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.1648 - accuracy: 0.9483\n",
      "Epoch 2/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9820\n",
      "Epoch 3/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0353 - accuracy: 0.9882\n",
      "Epoch 4/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0247 - accuracy: 0.9916\n",
      "Epoch 5/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0204 - accuracy: 0.9932\n",
      "313/313 [==============================] - 0s 745us/step - loss: 0.1291 - accuracy: 0.9738\n",
      "this is for t =  0.95\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.1817 - accuracy: 0.9436\n",
      "Epoch 2/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0661 - accuracy: 0.9792\n",
      "Epoch 3/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0423 - accuracy: 0.9866\n",
      "Epoch 4/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0317 - accuracy: 0.9892\n",
      "Epoch 5/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0236 - accuracy: 0.9918\n",
      "313/313 [==============================] - 0s 834us/step - loss: 0.1099 - accuracy: 0.9738\n",
      "this is for t =  0.98\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.1912 - accuracy: 0.9421\n",
      "Epoch 2/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0738 - accuracy: 0.9762\n",
      "Epoch 3/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0476 - accuracy: 0.9848\n",
      "Epoch 4/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0332 - accuracy: 0.9891\n",
      "Epoch 5/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0259 - accuracy: 0.9914\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9773\n",
      "this is for t =  0.99\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.2008 - accuracy: 0.9400\n",
      "Epoch 2/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9748\n",
      "Epoch 3/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0523 - accuracy: 0.9830\n",
      "Epoch 4/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0370 - accuracy: 0.9876\n",
      "Epoch 5/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0288 - accuracy: 0.9902\n",
      "313/313 [==============================] - 0s 826us/step - loss: 0.1012 - accuracy: 0.9718\n",
      "this is for t =  0.999\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1424 - accuracy: 0.9556\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0444 - accuracy: 0.9850\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0262 - accuracy: 0.9909\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0166 - accuracy: 0.9943\n",
      "313/313 [==============================] - 0s 760us/step - loss: 0.1806 - accuracy: 0.9695\n",
      "this is for t =  0.9\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1782/1782 [==============================] - 5s 3ms/step - loss: 0.1655 - accuracy: 0.9480\n",
      "Epoch 2/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0558 - accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0353 - accuracy: 0.9877\n",
      "Epoch 4/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 5/5\n",
      "1782/1782 [==============================] - 3s 2ms/step - loss: 0.0193 - accuracy: 0.9936\n",
      "313/313 [==============================] - 0s 765us/step - loss: 0.1392 - accuracy: 0.9721\n",
      "this is for t =  0.95\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.1823 - accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0678 - accuracy: 0.9780\n",
      "Epoch 3/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0429 - accuracy: 0.9859\n",
      "Epoch 4/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0292 - accuracy: 0.9908\n",
      "Epoch 5/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0233 - accuracy: 0.9919\n",
      "313/313 [==============================] - 0s 839us/step - loss: 0.0938 - accuracy: 0.9782\n",
      "this is for t =  0.98\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.1908 - accuracy: 0.9420\n",
      "Epoch 2/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0735 - accuracy: 0.9760\n",
      "Epoch 3/5\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 0.0471 - accuracy: 0.9849\n",
      "Epoch 4/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9890\n",
      "Epoch 5/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9917\n",
      "313/313 [==============================] - 0s 764us/step - loss: 0.1181 - accuracy: 0.9711\n",
      "this is for t =  0.99\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.1987 - accuracy: 0.9400\n",
      "Epoch 2/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0809 - accuracy: 0.9748\n",
      "Epoch 3/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0516 - accuracy: 0.9831\n",
      "Epoch 4/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0356 - accuracy: 0.9881\n",
      "Epoch 5/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0275 - accuracy: 0.9912\n",
      "313/313 [==============================] - 0s 733us/step - loss: 0.0892 - accuracy: 0.9744\n",
      "this is for t =  0.999\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1410 - accuracy: 0.9550\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0425 - accuracy: 0.9861\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0257 - accuracy: 0.9912\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0155 - accuracy: 0.9948\n",
      "313/313 [==============================] - 0s 761us/step - loss: 0.1801 - accuracy: 0.9664\n",
      "this is for t =  0.9\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.1687 - accuracy: 0.9475\n",
      "Epoch 2/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9809\n",
      "Epoch 3/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0359 - accuracy: 0.9884\n",
      "Epoch 4/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0243 - accuracy: 0.9916\n",
      "Epoch 5/5\n",
      "1782/1782 [==============================] - 4s 2ms/step - loss: 0.0192 - accuracy: 0.9936\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9709\n",
      "this is for t =  0.95\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.1822 - accuracy: 0.9437\n",
      "Epoch 2/5\n",
      "1838/1838 [==============================] - 3s 2ms/step - loss: 0.0662 - accuracy: 0.9783\n",
      "Epoch 3/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0430 - accuracy: 0.9860\n",
      "Epoch 4/5\n",
      "1838/1838 [==============================] - 4s 2ms/step - loss: 0.0307 - accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "1838/1838 [==============================] - 3s 2ms/step - loss: 0.0238 - accuracy: 0.9920\n",
      "313/313 [==============================] - 0s 776us/step - loss: 0.1083 - accuracy: 0.9740\n",
      "this is for t =  0.98\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1857/1857 [==============================] - 5s 3ms/step - loss: 0.1919 - accuracy: 0.9407\n",
      "Epoch 2/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0745 - accuracy: 0.9763\n",
      "Epoch 3/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0481 - accuracy: 0.9842\n",
      "Epoch 4/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0350 - accuracy: 0.9884\n",
      "Epoch 5/5\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 0.0254 - accuracy: 0.9921\n",
      "313/313 [==============================] - 0s 727us/step - loss: 0.0951 - accuracy: 0.9734\n",
      "this is for t =  0.99\n",
      "-------------------------------------------------\n",
      "Epoch 1/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.2005 - accuracy: 0.9392\n",
      "Epoch 2/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0802 - accuracy: 0.9746\n",
      "Epoch 3/5\n",
      "1874/1874 [==============================] - 4s 2ms/step - loss: 0.0514 - accuracy: 0.9838\n",
      "Epoch 4/5\n",
      "1874/1874 [==============================] - 3s 2ms/step - loss: 0.0362 - accuracy: 0.9884\n",
      "Epoch 5/5\n",
      "1874/1874 [==============================] - 3s 2ms/step - loss: 0.0271 - accuracy: 0.9914\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9763\n",
      "this is for t =  0.999\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mse_thresh = [0.9, 0.95, 0.98, 0.99, 0.999]\n",
    "for rs in range(5):        \n",
    "        tf.random.set_seed(rs)\n",
    "        for t in mse_thresh:\n",
    "                new_t = x_train_new['mse'].quantile(t)\n",
    "                new_index = x_train_new[x_train_new['mse']< new_t]['index']\n",
    "                clf = tf.keras.Sequential()\n",
    "                clf.add(tf.keras.layers.Flatten())\n",
    "                #clf.add(tf.keras.Input(shape=(28,28)))\n",
    "\n",
    "                clf.add(tf.keras.layers.Dense(756, activation='relu'))\n",
    "                clf.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "                clf.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "                clf.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "                clf.fit(x=x_train[new_index], y=y_train[new_index], epochs=5, )\n",
    "                clf.evaluate(x_test, y_test)\n",
    "                print('this is for t = ', t)\n",
    "                print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
